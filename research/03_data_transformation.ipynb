{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Data Science\\\\LoanApprovalAppWith-Mlflow\\\\Loan-APP\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Data Science\\\\LoanApprovalAppWith-Mlflow\\\\Loan-APP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loan_APP.constants import *\n",
    "from Loan_APP.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Loan_APP import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    # We can add all type of data transformation technique here. like PCA, Scaler, EDA\n",
    "    \n",
    "    def data_cleaning(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        data.drop('loan_id', axis =1 , inplace = True)\n",
    "        \n",
    "        nan_cat_feature = ['gender', 'married', 'self_employed', 'credit_history']\n",
    "        for col in nan_cat_feature:\n",
    "            data[col].fillna(data[col].mode()[0], inplace = True)\n",
    "            \n",
    "        nan_cont_feature = ['dependents', 'loanamount', 'loan_amount_term']\n",
    "        for col in nan_cont_feature:\n",
    "            data[col].fillna(data[col].median(), inplace = True)\n",
    "            \n",
    "        print(data.isnull().sum())\n",
    "        \n",
    "        df_obj = data.select_dtypes('O')\n",
    "        \n",
    "        lbl_ecoder = LabelEncoder()\n",
    "        for col in df_obj:\n",
    "            data[col] = lbl_ecoder.fit_transform(data[col])\n",
    "        \n",
    "        print(data.head())\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    def train_test_spliting(self, data):\n",
    "        # data = pd.read_csv(self.config.data_path)\n",
    "        \n",
    "        train, test = train_test_split(data, test_size=0.2, random_state= 42)\n",
    "        \n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"), index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"), index = False)\n",
    "        \n",
    "        logger.info(\"Splitted data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "        \n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-07 20:05:27,721: INFO: common: yaml file: config\\config.yaml is loaded successfully!]\n",
      "[2025-03-07 20:05:27,726: INFO: common: yaml file: params.yaml is loaded successfully!]\n",
      "[2025-03-07 20:05:27,737: INFO: common: yaml file: schema.yaml is loaded successfully!]\n",
      "[2025-03-07 20:05:27,742: INFO: common: created directory at: artifacts]\n",
      "[2025-03-07 20:05:27,747: INFO: common: created directory at: artifacts/data_transformation]\n",
      "gender               0\n",
      "married              0\n",
      "dependents           0\n",
      "education            0\n",
      "self_employed        0\n",
      "applicantincome      0\n",
      "coapplicantincome    0\n",
      "loanamount           0\n",
      "loan_amount_term     0\n",
      "credit_history       0\n",
      "property_area        0\n",
      "loan_status          0\n",
      "dtype: int64\n",
      "   gender  married  dependents  ...  credit_history  property_area  loan_status\n",
      "0       1        0         0.0  ...             1.0              2            1\n",
      "1       1        1         1.0  ...             1.0              0            0\n",
      "2       1        1         0.0  ...             1.0              2            1\n",
      "3       1        1         0.0  ...             1.0              2            1\n",
      "4       1        0         0.0  ...             1.0              2            1\n",
      "\n",
      "[5 rows x 12 columns]\n",
      "[2025-03-07 20:05:27,909: INFO: 768962064: Splitted data into training and test sets]\n",
      "[2025-03-07 20:05:27,911: INFO: 768962064: (491, 12)]\n",
      "[2025-03-07 20:05:27,913: INFO: 768962064: (123, 12)]\n",
      "(491, 12)\n",
      "(123, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_18652\\768962064.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace = True)\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_18652\\768962064.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace = True)\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_18652\\768962064.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace = True)\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_18652\\768962064.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    cleaned_df = data_transformation.data_cleaning()\n",
    "    data_transformation.train_test_spliting(cleaned_df)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
